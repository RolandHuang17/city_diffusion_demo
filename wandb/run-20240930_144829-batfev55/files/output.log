09/30/2024 14:48:31 - INFO - __main__ - ***** Running training *****
09/30/2024 14:48:31 - INFO - __main__ -   Num examples = 5228
09/30/2024 14:48:31 - INFO - __main__ -   Num Epochs = 12
09/30/2024 14:48:31 - INFO - __main__ -   Instantaneous batch size per device = 1
09/30/2024 14:48:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
09/30/2024 14:48:31 - INFO - __main__ -   Gradient Accumulation steps = 4
09/30/2024 14:48:31 - INFO - __main__ -   Total optimization steps = 15000
Steps:   3%|▏    | 500/15000 [01:16<34:57,  6.91it/s, lr=9.97e-5, step_loss=0.0144]09/30/2024 14:49:47 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500
[2024-09-30 14:48:33,289] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
[2024-09-30 14:48:33,465] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
[2024-09-30 14:48:33,636] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
[2024-09-30 14:48:33,793] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
[2024-09-30 14:48:33,937] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
[2024-09-30 14:48:34,080] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
[2024-09-30 14:48:34,223] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
[2024-09-30 14:48:34,645] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
[2024-09-30 14:48:34,939] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
[2024-09-30 14:48:35,654] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
[2024-09-30 14:48:38,695] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
09/30/2024 14:49:47 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:49:47,760] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:49:48,614] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:49:48,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:49:51,860] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:49:51,872] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:49:51,882] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:49:51,883] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:49:51,883] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:49:51 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_model
09/30/2024 14:49:51 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/scheduler.bin
09/30/2024 14:49:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/sampler.bin
09/30/2024 14:49:51 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500/pytorch_lora_weights.safetensors
09/30/2024 14:49:52 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-500
Steps:   7%|▎   | 1000/15000 [02:34<35:21,  6.60it/s, lr=9.89e-5, step_loss=0.0681]09/30/2024 14:51:05 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000
09/30/2024 14:51:05 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:51:05,772] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:51:06,660] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:51:06,660] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:51:09,968] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:51:09,981] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:51:09,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:51:09,992] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:51:09,992] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:51:09 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_model
09/30/2024 14:51:09 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/scheduler.bin
09/30/2024 14:51:09 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/sampler.bin
09/30/2024 14:51:09 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000/pytorch_lora_weights.safetensors
09/30/2024 14:51:10 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1000
Steps:  10%|▎  | 1500/15000 [03:52<32:41,  6.88it/s, lr=9.76e-5, step_loss=0.00547]09/30/2024 14:52:23 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500
[2024-09-30 14:51:57,596] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
09/30/2024 14:52:23 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:52:23,676] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:52:24,530] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:52:24,530] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:52:27,665] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:52:27,677] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:52:27,688] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:52:27,688] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:52:27,688] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:52:27 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_model
09/30/2024 14:52:27 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/scheduler.bin
09/30/2024 14:52:27 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/sampler.bin
09/30/2024 14:52:27 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500/pytorch_lora_weights.safetensors
09/30/2024 14:52:27 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-1500
Steps:  13%|▌   | 2000/15000 [05:10<31:15,  6.93it/s, lr=9.57e-5, step_loss=0.0261]09/30/2024 14:53:42 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000
[2024-09-30 14:53:11,440] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
09/30/2024 14:53:42 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:53:42,219] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:53:43,079] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:53:43,079] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:53:46,272] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:53:46,284] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:53:46,295] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:53:46,295] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:53:46,295] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:53:46 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_model
09/30/2024 14:53:46 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/scheduler.bin
09/30/2024 14:53:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/sampler.bin
09/30/2024 14:53:46 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000/pytorch_lora_weights.safetensors
09/30/2024 14:53:46 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2000
Steps:  17%|▋   | 2500/15000 [06:27<30:27,  6.84it/s, lr=9.34e-5, step_loss=0.0886]09/30/2024 14:54:59 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500
09/30/2024 14:54:59 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:54:59,124] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:55:00,023] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:55:00,024] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:55:03,244] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:55:03,257] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:55:03,268] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:55:03,269] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:55:03,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:55:03 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_model
09/30/2024 14:55:03 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/scheduler.bin
09/30/2024 14:55:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/sampler.bin
09/30/2024 14:55:03 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500/pytorch_lora_weights.safetensors
09/30/2024 14:55:03 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-2500
Steps:  20%|█    | 3000/15000 [07:45<28:52,  6.92it/s, lr=9.05e-5, step_loss=0.026]09/30/2024 14:56:16 - INFO - accelerate.accelerator - Saving current state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000
09/30/2024 14:56:16 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2024-09-30 14:56:16,548] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-09-30 14:56:17,415] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt
[2024-09-30 14:56:17,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt...
[2024-09-30 14:56:20,617] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/mp_rank_00_model_states.pt.
[2024-09-30 14:56:20,630] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-30 14:56:20,640] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-30 14:56:20,641] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-30 14:56:20,641] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/30/2024 14:56:20 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_model
09/30/2024 14:56:20 - INFO - accelerate.checkpointing - Scheduler state saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/scheduler.bin
09/30/2024 14:56:20 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/sampler.bin
09/30/2024 14:56:20 - INFO - accelerate.checkpointing - Random states saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/random_states_0.pkl
Model weights saved in root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000/pytorch_lora_weights.safetensors
09/30/2024 14:56:20 - INFO - __main__ - Saved state to root/autodl-tmp/sddata/finetune/lora/city/checkpoint-3000
Steps:  22%|▋  | 3278/15000 [08:30<30:20,  6.44it/s, lr=8.88e-5, step_loss=0.00828]Traceback (most recent call last):
  File "/root/autodl-tmp/Proj/city_diffusion_demo/train_lora.py", line 979, in <module>
    main()
  File "/root/autodl-tmp/Proj/city_diffusion_demo/train_lora.py", line 831, in main
    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states, return_dict=False)[0]
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
    loss = self.module(*inputs, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_condition.py", line 1216, in forward
    sample, res_samples = downsample_block(
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
    hidden_states = attn(
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py", line 442, in forward
    hidden_states = block(
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention.py", line 466, in forward
    attn_output = self.attn1(
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 490, in forward
    return self.processor(
  File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 2367, in __call__
    hidden_states = F.scaled_dot_product_attention(
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/autodl-tmp/Proj/city_diffusion_demo/train_lora.py", line 979, in <module>
[rank0]:     main()
[rank0]:   File "/root/autodl-tmp/Proj/city_diffusion_demo/train_lora.py", line 831, in main
[rank0]:     model_pred = unet(noisy_latents, timesteps, encoder_hidden_states, return_dict=False)[0]
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank0]:     loss = self.module(*inputs, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_condition.py", line 1216, in forward
[rank0]:     sample, res_samples = downsample_block(
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
[rank0]:     hidden_states = attn(
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/transformers/transformer_2d.py", line 442, in forward
[rank0]:     hidden_states = block(
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention.py", line 466, in forward
[rank0]:     attn_output = self.attn1(
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 490, in forward
[rank0]:     return self.processor(
[rank0]:   File "/root/miniconda3/envs/diff/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 2367, in __call__
[rank0]:     hidden_states = F.scaled_dot_product_attention(
[rank0]: KeyboardInterrupt
