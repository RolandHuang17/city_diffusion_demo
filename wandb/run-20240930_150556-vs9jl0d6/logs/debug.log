2024-09-30 15:05:56,787 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Current SDK version is 0.18.2
2024-09-30 15:05:56,788 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Configure stats pid to 13475
2024-09-30 15:05:56,788 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Loading settings from /root/.config/wandb/settings
2024-09-30 15:05:56,788 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Loading settings from /root/autodl-tmp/Proj/city_diffusion_demo/wandb/settings
2024-09-30 15:05:56,789 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-09-30 15:05:56,789 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-09-30 15:05:56,789 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'train_lora.py', 'program_abspath': '/root/autodl-tmp/Proj/city_diffusion_demo/train_lora.py', 'program': './train_lora.py'}
2024-09-30 15:05:56,789 INFO    MainThread:13475 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-09-30 15:05:56,790 INFO    MainThread:13475 [wandb_init.py:_log_setup():532] Logging user logs to /root/autodl-tmp/Proj/city_diffusion_demo/wandb/run-20240930_150556-vs9jl0d6/logs/debug.log
2024-09-30 15:05:56,790 INFO    MainThread:13475 [wandb_init.py:_log_setup():533] Logging internal logs to /root/autodl-tmp/Proj/city_diffusion_demo/wandb/run-20240930_150556-vs9jl0d6/logs/debug-internal.log
2024-09-30 15:05:56,791 INFO    MainThread:13475 [wandb_init.py:init():616] calling init triggers
2024-09-30 15:05:56,791 INFO    MainThread:13475 [wandb_init.py:init():623] wandb.init called with sweep_config: {}
config: {}
2024-09-30 15:05:56,792 INFO    MainThread:13475 [wandb_init.py:init():666] starting backend
2024-09-30 15:05:56,792 INFO    MainThread:13475 [wandb_init.py:init():670] sending inform_init request
2024-09-30 15:05:56,802 INFO    MainThread:13475 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-09-30 15:05:56,804 INFO    MainThread:13475 [wandb_init.py:init():683] backend started and connected
2024-09-30 15:05:56,825 INFO    MainThread:13475 [wandb_init.py:init():778] updated telemetry
2024-09-30 15:05:56,870 INFO    MainThread:13475 [wandb_init.py:init():811] communicating run to backend with 90.0 second timeout
2024-09-30 15:05:57,485 INFO    MainThread:13475 [wandb_init.py:init():862] starting run threads in backend
2024-09-30 15:05:57,893 INFO    MainThread:13475 [wandb_run.py:_console_start():2464] atexit reg
2024-09-30 15:05:57,893 INFO    MainThread:13475 [wandb_run.py:_redirect():2312] redirect: wrap_raw
2024-09-30 15:05:57,893 INFO    MainThread:13475 [wandb_run.py:_redirect():2377] Wrapping output streams.
2024-09-30 15:05:57,894 INFO    MainThread:13475 [wandb_run.py:_redirect():2402] Redirects installed.
2024-09-30 15:05:57,898 INFO    MainThread:13475 [wandb_init.py:init():906] run started, returning control to user process
2024-09-30 15:05:57,902 INFO    MainThread:13475 [wandb_run.py:_config_callback():1393] config_cb None None {'pretrained_model_name_or_path': 'runwayml/stable-diffusion-v1-5', 'revision': None, 'variant': None, 'dataset_name': '/root/autodl-tmp/Proj/city_diffusion_demo/data', 'dataset_config_name': None, 'train_data_dir': None, 'image_column': 'image', 'caption_column': 'text', 'validation_prompt': 'Buildings in Wuhan', 'num_validation_images': 4, 'validation_epochs': 1, 'max_train_samples': None, 'output_dir': '/root/autodl-tmp/root/autodl-tmp/sddata/finetune/lora/city', 'cache_dir': None, 'seed': 1337, 'resolution': 128, 'center_crop': True, 'random_flip': True, 'train_batch_size': 1, 'num_train_epochs': 12, 'max_train_steps': 15000, 'gradient_accumulation_steps': 4, 'gradient_checkpointing': False, 'learning_rate': 0.0001, 'scale_lr': False, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 0, 'snr_gamma': None, 'use_8bit_adam': False, 'allow_tf32': False, 'dataloader_num_workers': 8, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'push_to_hub': True, 'hub_token': None, 'prediction_type': None, 'hub_model_id': 'pokemon-lora', 'logging_dir': 'logs', 'mixed_precision': None, 'report_to': 'wandb', 'local_rank': -1, 'checkpointing_steps': 500, 'checkpoints_total_limit': None, 'resume_from_checkpoint': None, 'enable_xformers_memory_efficient_attention': False, 'noise_offset': 0, 'rank': 4}
